{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict,Counter\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import numpy as np\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "from itertools import islice,count\n",
    "from contextlib import closing\n",
    "\n",
    "import json\n",
    "from io import StringIO\n",
    "from pathlib import Path\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TF-IDF Using TfidfVectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "def tf_idf_scores(data):\n",
    "    \"\"\"\n",
    "    This function calculates the tfidf for each word in a single document utilizing TfidfVectorizer via sklearn.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "      data: list of strings.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "      Two objects as follows:\n",
    "                                a) DataFrame, documents as rows (i.e., 0,1,2,3, etc'), terms as columns ('bird','bright', etc').\n",
    "                                b) TfidfVectorizer object.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    return pd.DataFrame(vectorizer.fit_transform(data).toarray(), columns=vectorizer.get_feature_names_out()), vectorizer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cosine Similarity Using Sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "def cosine_sim_using_sklearn(queries,tfidf):\n",
    "    \"\"\"\n",
    "    In this function you need to utilize the cosine_similarity function from sklearn.\n",
    "    You need to compute the similarity between the queries and the given documents.\n",
    "    This function will return a DataFrame in the following shape: (# of queries, # of documents).\n",
    "    Each value in the DataFrame will represent the cosine_similarity between given query and document.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "      queries: sparse matrix represent the queries after transformation of tfidfvectorizer.\n",
    "      documents: sparse matrix represent the documents.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "      DataFrame: This function will return a DataFrame in the following shape: (# of queries, # of documents).\n",
    "      Each value in the DataFrame will represent the cosine_similarity between given query and document.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return pd.DataFrame(cosine_similarity(queries, tfidf))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BM25"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[['sky', 'blue', 'see', 'blue', 'sun'],\n",
       " ['sun', 'bright', 'yellow'],\n",
       " ['comes', 'blue', 'sun'],\n",
       " ['lucy', 'sky', 'diamonds', 'see', 'sun', 'sky'],\n",
       " ['sun', 'sun', 'blue', 'sun', 'come'],\n",
       " ['lucy', 'likes', 'blue', 'bright', 'diamonds']]"
      ]
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "RE_WORD = re.compile(r\"\"\"[\\#\\@\\w](['\\-]?\\w){2,24}\"\"\", re.UNICODE)\n",
    "stopwords_frozen = frozenset(stopwords.words('english'))\n",
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    This function aims in tokenize a text into a list of tokens. Moreover, it filters stopwords.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    text: string , repressing the text to tokenize.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    list of tokens (e.g., list of tokens).\n",
    "    \"\"\"\n",
    "    list_of_tokens =  [token.group() for token in RE_WORD.finditer(text.lower()) if token.group() not in stopwords_frozen]\n",
    "    return list_of_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class BM25:\n",
    "    \"\"\"\n",
    "    Best Match 25.\n",
    "\n",
    "    Parameters to tune\n",
    "    ----------\n",
    "    k1 : float, default 1.5\n",
    "\n",
    "    b : float, default 0.75\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    tf_ : list[dict[str, int]]\n",
    "        Term Frequency per document, normalized by document's length.\n",
    "\n",
    "    doc_len_ : list[int]\n",
    "        Number of terms per document.\n",
    "\n",
    "    df_ : dict[str, int]\n",
    "        Document Frequency per term. i.e. Number of documents in the\n",
    "        corpus that contains the term.\n",
    "\n",
    "    avg_dl_ : float\n",
    "        Average number of terms for documents in the corpus.\n",
    "\n",
    "    idf_ : dict[str, float]\n",
    "        Inverse Document Frequency per term.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, doc_len, df, tf=None, k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "        self.tf_ = tf\n",
    "        self.doc_len_ = doc_len\n",
    "        self.df_ = df\n",
    "        self.N_ = len(doc_len)\n",
    "        self.avg_dl_ = sum(doc_len) / len(doc_len)\n",
    "        self.idf_ = {}\n",
    "\n",
    "    def calc_idf(self, query):\n",
    "        \"\"\"\n",
    "        This function calculate the idf values according to the BM25 idf formula for each term in the query.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query: list of token representing the query.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        idf: dictionary of idf scores. As follows:\n",
    "                                                    key: term\n",
    "                                                    value: bm25 idf score\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        idf = {}\n",
    "\n",
    "        for term in query:\n",
    "            freq = 0\n",
    "            if self.df_.get(term):\n",
    "                freq = self.df_[term]\n",
    "            idf[term] = math.log((self.N_ - freq + 0.5) / (freq + 0.5) + 1)\n",
    "\n",
    "        return idf\n",
    "\n",
    "    def search(self, queries):\n",
    "        \"\"\"\n",
    "        This function use the _score function to calculate the bm25 score for all queries provided.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        queries: list of lists. Each inner list is a list of tokens.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        list of scores of bm25\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for query in queries:\n",
    "            scores.append([self._score(query, doc_id) for doc_id in range(self.N_)])\n",
    "        return scores\n",
    "\n",
    "    def _score(self, query, doc_id):\n",
    "        \"\"\"\n",
    "        This function calculate the bm25 score for given query and document.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
    "        doc_id: integer, document id.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        score: float, bm25 score.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        score = 0.0\n",
    "\n",
    "        if self.tf_:\n",
    "            intersection = list(filter(lambda t: t in self.tf_[doc_id].keys(), query))\n",
    "            b_calc = 1 - self.b + self.b * (self.doc_len_[doc_id] / self.avg_dl_)\n",
    "\n",
    "            for term in intersection:\n",
    "                score += ((self.k1 + 1) * self.tf_[doc_id][term]) / (\n",
    "                            b_calc * self.k1 + self.tf_[doc_id][term]) * math.log2((self.N_ + 1) / self.df_[term])\n",
    "\n",
    "        return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def top_N_documents(df,N):\n",
    "    \"\"\"\n",
    "    This function sort and filter the top N documents (by score) for each query.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame (queries as rows, documents as columns)\n",
    "    N: Integer (how many document to retrieve for each query)\n",
    "\n",
    "    Returns:\n",
    "    ----------\n",
    "    top_N: dictionary is the following structure:\n",
    "          key - query id.\n",
    "          value - sorted (according to score) list of pairs length of N. Eac pair within the list provide the following information (doc id, score)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    result = {}\n",
    "\n",
    "    for query_id, row in df.iterrows():\n",
    "      doc_score = row.nlargest(N)\n",
    "      result[query_id] = [(doc_id, score) for doc_id, score in doc_score.items()]\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "def generate_query_tfidf_vector(query_to_search, index):\n",
    "    \"\"\"\n",
    "    Generate a vector representing the query. Each entry within this vector represents a tfidf score.\n",
    "    The terms representing the query will be the unique terms in the index.\n",
    "\n",
    "    We will use tfidf on the query as well.\n",
    "    For calculation of IDF, use log with base 10.\n",
    "    tf will be normalized based on the length of the query.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.').\n",
    "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
    "\n",
    "    index:           inverted index loaded from the corresponding files.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    vectorized query with tfidf scores\n",
    "    \"\"\"\n",
    "    epsilon = .0000001\n",
    "    total_vocab_size = len(index.term_total)\n",
    "    Q = np.zeros(total_vocab_size)\n",
    "    term_vector = list(index.term_total.keys())\n",
    "    counter = Counter(query_to_search)\n",
    "\n",
    "    for token in np.unique(query_to_search):\n",
    "        if token in index.term_total.keys(): #avoid terms that do not appear in the index.\n",
    "            tf = counter[token] / len(query_to_search) # term frequency divded by the length of the query\n",
    "            df = index.df[token]\n",
    "            idf = math.log((len(index.dl)) / (df+epsilon), 10) #smoothing\n",
    "\n",
    "            try:\n",
    "                ind = term_vector.index(token)\n",
    "                Q[ind] = tf*idf\n",
    "            except:\n",
    "                pass\n",
    "    return Q"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [],
   "source": [
    "def get_candidate_documents_and_scores(query_to_search, index, words, pls):\n",
    "    \"\"\"\n",
    "    Generate a dictionary representing a pool of candidate documents for a given query. This function will go through every token in query_to_search\n",
    "    and fetch the corresponding information (e.g., term frequency, document frequency, etc.') needed to calculate TF-IDF from the posting list.\n",
    "    Then it will populate the dictionary 'candidates.'\n",
    "    For calculation of IDF, use log with base 10.\n",
    "    tf will be normalized based on the length of the document.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.').\n",
    "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
    "\n",
    "    index:           inverted index loaded from the corresponding files.\n",
    "\n",
    "    words,pls: iterator for working with posting.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    dictionary of candidates. In the following format:\n",
    "                                                               key: pair (doc_id,term)\n",
    "                                                               value: tfidf score.\n",
    "    \"\"\"\n",
    "    candidates = {}\n",
    "    for term in np.unique(query_to_search):\n",
    "        if term in words:\n",
    "            list_of_doc = pls[words.index(term)]\n",
    "            normalized_tfidf = [(doc_id, (freq / index.dl[str(doc_id)]) * math.log(len(index.dl) / index.df[term], 10)) for doc_id, freq in list_of_doc]\n",
    "\n",
    "            for doc_id, tfidf in normalized_tfidf:\n",
    "                candidates[(doc_id,term)] = candidates.get((doc_id,term), 0) + tfidf\n",
    "\n",
    "    return candidates"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "def generate_document_tfidf_matrix(query_to_search,index,words,pls):\n",
    "    \"\"\"\n",
    "    Generate a DataFrame `D` of tfidf scores for a given query.\n",
    "    Rows will be the documents candidates for a given query\n",
    "    Columns will be the unique terms in the index.\n",
    "    The value for a given document and term will be its tfidf score.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_to_search: list of tokens (str). This list will be preprocessed in advance (e.g., lower case, filtering stopwords, etc.').\n",
    "                     Example: 'Hello, I love information retrival' --->  ['hello','love','information','retrieval']\n",
    "\n",
    "    index:           inverted index loaded from the corresponding files.\n",
    "\n",
    "\n",
    "    words,pls: iterator for working with posting.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    DataFrame of tfidf scores.\n",
    "    \"\"\"\n",
    "\n",
    "    total_vocab_size = len(index.term_total)\n",
    "    candidates_scores = get_candidate_documents_and_scores(query_to_search, index, words, pls) #No need to utilize all documents, only those having corresponding terms with the query.\n",
    "    unique_candidates = np.unique([doc_id for doc_id, freq in candidates_scores.keys()])\n",
    "    D = np.zeros((len(unique_candidates), total_vocab_size))\n",
    "    D = pd.DataFrame(D)\n",
    "\n",
    "    D.index = unique_candidates\n",
    "    D.columns = index.term_total.keys()\n",
    "\n",
    "    for key in candidates_scores:\n",
    "        tfidf = candidates_scores[key]\n",
    "        doc_id, term = key\n",
    "        D.loc[doc_id][term] = tfidf\n",
    "\n",
    "    return D"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "outputs": [],
   "source": [
    "def cosine_similarity(D,Q):\n",
    "    \"\"\"\n",
    "    Calculate the cosine similarity for each candidate document in D and a given query (e.g., Q).\n",
    "    Generate a dictionary of cosine similarity scores\n",
    "    key: doc_id\n",
    "    value: cosine similarity score\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    D: DataFrame of tfidf scores.\n",
    "\n",
    "    Q: vectorized query with tfidf scores\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    dictionary of cosine similarity score as follows:\n",
    "                                                                key: document id (e.g., doc_id)\n",
    "                                                                value: cosine similarty score.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    result = {}\n",
    "\n",
    "    for doc_id, scores in D.iterrows():\n",
    "      s = np.array(scores)\n",
    "      result[doc_id] =np.dot(s,Q) / (np.linalg.norm(s) * np.linalg.norm(Q))\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [],
   "source": [
    "def get_top_n(sim_dict,N=3):\n",
    "    \"\"\"\n",
    "    Sort and return the highest N documents according to the cosine similarity score.\n",
    "    Generate a dictionary of cosine similarity scores\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    sim_dict: a dictionary of similarity score as follows:\n",
    "                                                                key: document id (e.g., doc_id)\n",
    "                                                                value: similarity score. We keep up to 5 digits after the decimal point. (e.g., round(score,5))\n",
    "\n",
    "    N: Integer (how many documents to retrieve). By default N = 3\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    a ranked list of pairs (doc_id, score) in the length of N.\n",
    "    \"\"\"\n",
    "\n",
    "    return sorted([(doc_id,round(score,5)) for doc_id, score in sim_dict.items()], key = lambda x: x[1],reverse=True)[:N]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "def get_topN_score_for_queries(queries_to_search,index,N=3):\n",
    "    \"\"\"\n",
    "    Generate a dictionary that gathers for every query its topN score.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    queries_to_search: a dictionary of queries as follows:\n",
    "                                                        key: query_id\n",
    "                                                        value: list of tokens.\n",
    "    index:           inverted index loaded from the corresponding files.\n",
    "    N: Integer. How many documents to retrieve. This argument is passed to the topN function. By default N = 3, for the topN function.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    return: a dictionary of queries and topN pairs as follows:\n",
    "                                                        key: query_id\n",
    "                                                        value: list of pairs in the following format:(doc_id, score).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    result = {}\n",
    "\n",
    "    for id, query in queries_to_search.items():\n",
    "      words, pls = get_posting_iter(index)\n",
    "      D = generate_document_tfidf_matrix(query, index, words, pls)\n",
    "      Q = generate_query_tfidf_vector(query, index)\n",
    "      result[id] = get_top_n(cosine_similarity(D,Q), N)\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import chain\n",
    "import time\n",
    "# When preprocessing the data have a dictionary of document length for each document saved in a variable called `DL`.\n",
    "class BM25_from_index:\n",
    "    \"\"\"\n",
    "    Best Match 25.\n",
    "    ----------\n",
    "    k1 : float, default 1.5\n",
    "\n",
    "    b : float, default 0.75\n",
    "\n",
    "    index: inverted index\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,index,k1=1.5, b=0.75):\n",
    "        self.b = b\n",
    "        self.k1 = k1\n",
    "        self.index = index\n",
    "        self.N = len(DL)\n",
    "        self.AVGDL = sum(DL.values())/self.N\n",
    "        self.words, self.pls = zip(*self.index.posting_lists_iter())\n",
    "\n",
    "    def calc_idf(self,list_of_tokens):\n",
    "        \"\"\"\n",
    "        This function calculate the idf values according to the BM25 idf formula for each term in the query.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        idf: dictionary of idf scores. As follows:\n",
    "                                                    key: term\n",
    "                                                    value: bm25 idf score\n",
    "        \"\"\"\n",
    "        idf = {}\n",
    "        for term in list_of_tokens:\n",
    "            if term in self.index.df.keys():\n",
    "                n_ti = self.index.df[term]\n",
    "                idf[term] = math.log(1 + (self.N - n_ti + 0.5) / (n_ti + 0.5))\n",
    "            else:\n",
    "                pass\n",
    "        return idf\n",
    "\n",
    "\n",
    "    def search(self, queries,N=3):\n",
    "        \"\"\"\n",
    "        This function calculate the bm25 score for given query and document.\n",
    "        We need to check only documents which are 'candidates' for a given query.\n",
    "        This function return a dictionary of scores as the following:\n",
    "                                                                    key: query_id\n",
    "                                                                    value: a ranked list of pairs (doc_id, score) in the length of N.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
    "        doc_id: integer, document id.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        score: float, bm25 score.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        result = {}\n",
    "\n",
    "        for query_id, query in queries.items():\n",
    "          self.idf = self.calc_idf(query)\n",
    "          candidates = set()\n",
    "\n",
    "          for term in np.unique(query):\n",
    "            if term in self.words:\n",
    "              candidates.update(doc_freq[0] for doc_freq in self.pls[self.words.index(term)])\n",
    "\n",
    "          result[query_id] = sorted([(doc_id, self._score(query, doc_id)) for doc_id in candidates], key=lambda x: x[1], reverse=True)[:min(N, self.N)]\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def _score(self, query, doc_id):\n",
    "        \"\"\"\n",
    "        This function calculate the bm25 score for given query and document.\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        query: list of token representing the query. For example: ['look', 'blue', 'sky']\n",
    "        doc_id: integer, document id.\n",
    "\n",
    "        Returns:\n",
    "        -----------\n",
    "        score: float, bm25 score.\n",
    "        \"\"\"\n",
    "        score = 0.0\n",
    "        doc_len = DL[str(doc_id)]\n",
    "\n",
    "        for term in query:\n",
    "            if term in self.index.term_total.keys():\n",
    "                term_frequencies = dict(self.pls[self.words.index(term)])\n",
    "                if doc_id in term_frequencies.keys():\n",
    "                    freq = term_frequencies[doc_id]\n",
    "                    numerator = self.idf[term] * freq * (self.k1 + 1)\n",
    "                    denominator = freq + self.k1 * (1 - self.b + self.b * doc_len / self.AVGDL)\n",
    "                    score += (numerator / denominator)\n",
    "        return score"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 3: Using weights of title and body scores (25 points)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "outputs": [],
   "source": [
    "def merge_results(title_scores,body_scores,title_weight=0.5,text_weight=0.5,N = 3):\n",
    "    \"\"\"\n",
    "    This function merge and sort documents retrieved by its weighte score (e.g., title and body).\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    title_scores: a dictionary build upon the title index of queries and tuples representing scores as follows:\n",
    "                                                                            key: query_id\n",
    "                                                                            value: list of pairs in the following format:(doc_id,score)\n",
    "\n",
    "    body_scores: a dictionary build upon the body/text index of queries and tuples representing scores as follows:\n",
    "                                                                            key: query_id\n",
    "                                                                            value: list of pairs in the following format:(doc_id,score)\n",
    "    title_weight: float, for weigted average utilizing title and body scores\n",
    "    text_weight: float, for weigted average utilizing title and body scores\n",
    "    N: Integer. How many document to retrieve. This argument is passed to topN function. By default N = 3, for the topN function.\n",
    "\n",
    "    Returns:\n",
    "    -----------\n",
    "    dictionary of querires and topN pairs as follows:\n",
    "                                                        key: query_id\n",
    "                                                        value: list of pairs in the following format:(doc_id,score).\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    weighten_title_scores = {}\n",
    "    for query_id in title_scores.keys():\n",
    "      weighten_title_scores[query_id] = [(doc, score * title_weight) for doc, score in title_scores[query_id]]\n",
    "\n",
    "    weighten_body_scores = {}\n",
    "    for query_id in body_scores.keys():\n",
    "      weighten_body_scores[query_id] = [(doc, score * text_weight) for doc, score in body_scores[query_id]]\n",
    "\n",
    "    merged_scores = weighten_title_scores\n",
    "\n",
    "    for query_id, docs_scores in weighten_body_scores.items():\n",
    "      if merged_scores.get(query_id):\n",
    "        merged_docs = {doc_id: score for doc_id, score in merged_scores[query_id]}\n",
    "\n",
    "        for doc, score in docs_scores:\n",
    "          if not merged_docs.get(doc):\n",
    "            merged_docs[doc] = 0\n",
    "          merged_docs[doc] += score\n",
    "\n",
    "        merged_scores[query_id] = [(doc, score) for doc, score in merged_docs.items()]\n",
    "\n",
    "      else:\n",
    "        merged_scores[query_id] = weighten_body_scores[query_id]\n",
    "\n",
    "      merged_scores[query_id] = sorted(merged_scores[query_id], key=lambda x: x[1], reverse=True)[:min(N, len(merged_scores[query_id]))]\n",
    "\n",
    "    return merged_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}